{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:50:12.637475524Z",
     "start_time": "2024-03-23T15:50:10.801871864Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 11:50:10.944529: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-23 11:50:10.969786: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-23 11:50:10.969824: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-23 11:50:10.969852: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-23 11:50:10.975683: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-23 11:50:11.617678: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 11:50:12.612716: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 11:50:12.633987: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 11:50:12.634213: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 11:50:12.634577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import utils\n",
    "from tensorflow.keras import mixed_precision\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_path = \"BIRDS1_split/train\"\n",
    "test_data_path = \"BIRDS1_split/test\"\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 32\n",
    "bird_classes = sorted(os.listdir(train_data_path))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:50:12.641135092Z",
     "start_time": "2024-03-23T15:50:12.638809962Z"
    }
   },
   "id": "6ef16eed851f94c6",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25744 files belonging to 167 classes.\n",
      "Using 18021 files for training.\n",
      "Found 25744 files belonging to 167 classes.\n",
      "Using 7723 files for validation.\n",
      "Found 11545 files belonging to 167 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T16:16:56.871756752Z",
     "start_time": "2024-03-23T16:16:55.453923696Z"
    }
   },
   "id": "727dfbfe4c00fe25",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v3.preprocess_input\n",
    "train_dataset = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "validation_dataset = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T16:17:04.053234289Z",
     "start_time": "2024-03-23T16:17:04.032610246Z"
    }
   },
   "id": "10dd6962d0bf3fe8",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "rescaling\n",
      "Conv\n",
      "Conv/BatchNorm\n",
      "tf.math.add\n",
      "re_lu\n",
      "tf.math.multiply\n",
      "multiply\n",
      "expanded_conv/depthwise/pad\n",
      "expanded_conv/depthwise\n",
      "expanded_conv/depthwise/BatchNorm\n",
      "re_lu_1\n",
      "expanded_conv/squeeze_excite/AvgPool\n",
      "expanded_conv/squeeze_excite/Conv\n",
      "expanded_conv/squeeze_excite/Relu\n",
      "expanded_conv/squeeze_excite/Conv_1\n",
      "tf.math.add_1\n",
      "re_lu_2\n",
      "tf.math.multiply_1\n",
      "expanded_conv/squeeze_excite/Mul\n",
      "expanded_conv/project\n",
      "expanded_conv/project/BatchNorm\n",
      "expanded_conv_1/expand\n",
      "expanded_conv_1/expand/BatchNorm\n",
      "re_lu_3\n",
      "expanded_conv_1/depthwise/pad\n",
      "expanded_conv_1/depthwise\n",
      "expanded_conv_1/depthwise/BatchNorm\n",
      "re_lu_4\n",
      "expanded_conv_1/project\n",
      "expanded_conv_1/project/BatchNorm\n",
      "expanded_conv_2/expand\n",
      "expanded_conv_2/expand/BatchNorm\n",
      "re_lu_5\n",
      "expanded_conv_2/depthwise\n",
      "expanded_conv_2/depthwise/BatchNorm\n",
      "re_lu_6\n",
      "expanded_conv_2/project\n",
      "expanded_conv_2/project/BatchNorm\n",
      "expanded_conv_2/Add\n",
      "expanded_conv_3/expand\n",
      "expanded_conv_3/expand/BatchNorm\n",
      "tf.math.add_2\n",
      "re_lu_7\n",
      "tf.math.multiply_2\n",
      "multiply_1\n",
      "expanded_conv_3/depthwise/pad\n",
      "expanded_conv_3/depthwise\n",
      "expanded_conv_3/depthwise/BatchNorm\n",
      "tf.math.add_3\n",
      "re_lu_8\n",
      "tf.math.multiply_3\n",
      "multiply_2\n",
      "expanded_conv_3/squeeze_excite/AvgPool\n",
      "expanded_conv_3/squeeze_excite/Conv\n",
      "expanded_conv_3/squeeze_excite/Relu\n",
      "expanded_conv_3/squeeze_excite/Conv_1\n",
      "tf.math.add_4\n",
      "re_lu_9\n",
      "tf.math.multiply_4\n",
      "expanded_conv_3/squeeze_excite/Mul\n",
      "expanded_conv_3/project\n",
      "expanded_conv_3/project/BatchNorm\n",
      "expanded_conv_4/expand\n",
      "expanded_conv_4/expand/BatchNorm\n",
      "tf.math.add_5\n",
      "re_lu_10\n",
      "tf.math.multiply_5\n",
      "multiply_3\n",
      "expanded_conv_4/depthwise\n",
      "expanded_conv_4/depthwise/BatchNorm\n",
      "tf.math.add_6\n",
      "re_lu_11\n",
      "tf.math.multiply_6\n",
      "multiply_4\n",
      "expanded_conv_4/squeeze_excite/AvgPool\n",
      "expanded_conv_4/squeeze_excite/Conv\n",
      "expanded_conv_4/squeeze_excite/Relu\n",
      "expanded_conv_4/squeeze_excite/Conv_1\n",
      "tf.math.add_7\n",
      "re_lu_12\n",
      "tf.math.multiply_7\n",
      "expanded_conv_4/squeeze_excite/Mul\n",
      "expanded_conv_4/project\n",
      "expanded_conv_4/project/BatchNorm\n",
      "expanded_conv_4/Add\n",
      "expanded_conv_5/expand\n",
      "expanded_conv_5/expand/BatchNorm\n",
      "tf.math.add_8\n",
      "re_lu_13\n",
      "tf.math.multiply_8\n",
      "multiply_5\n",
      "expanded_conv_5/depthwise\n",
      "expanded_conv_5/depthwise/BatchNorm\n",
      "tf.math.add_9\n",
      "re_lu_14\n",
      "tf.math.multiply_9\n",
      "multiply_6\n",
      "expanded_conv_5/squeeze_excite/AvgPool\n",
      "expanded_conv_5/squeeze_excite/Conv\n",
      "expanded_conv_5/squeeze_excite/Relu\n",
      "expanded_conv_5/squeeze_excite/Conv_1\n",
      "tf.math.add_10\n",
      "re_lu_15\n",
      "tf.math.multiply_10\n",
      "expanded_conv_5/squeeze_excite/Mul\n",
      "expanded_conv_5/project\n",
      "expanded_conv_5/project/BatchNorm\n",
      "expanded_conv_5/Add\n",
      "expanded_conv_6/expand\n",
      "expanded_conv_6/expand/BatchNorm\n",
      "tf.math.add_11\n",
      "re_lu_16\n",
      "tf.math.multiply_11\n",
      "multiply_7\n",
      "expanded_conv_6/depthwise\n",
      "expanded_conv_6/depthwise/BatchNorm\n",
      "tf.math.add_12\n",
      "re_lu_17\n",
      "tf.math.multiply_12\n",
      "multiply_8\n",
      "expanded_conv_6/squeeze_excite/AvgPool\n",
      "expanded_conv_6/squeeze_excite/Conv\n",
      "expanded_conv_6/squeeze_excite/Relu\n",
      "expanded_conv_6/squeeze_excite/Conv_1\n",
      "tf.math.add_13\n",
      "re_lu_18\n",
      "tf.math.multiply_13\n",
      "expanded_conv_6/squeeze_excite/Mul\n",
      "expanded_conv_6/project\n",
      "expanded_conv_6/project/BatchNorm\n",
      "expanded_conv_7/expand\n",
      "expanded_conv_7/expand/BatchNorm\n",
      "tf.math.add_14\n",
      "re_lu_19\n",
      "tf.math.multiply_14\n",
      "multiply_9\n",
      "expanded_conv_7/depthwise\n",
      "expanded_conv_7/depthwise/BatchNorm\n",
      "tf.math.add_15\n",
      "re_lu_20\n",
      "tf.math.multiply_15\n",
      "multiply_10\n",
      "expanded_conv_7/squeeze_excite/AvgPool\n",
      "expanded_conv_7/squeeze_excite/Conv\n",
      "expanded_conv_7/squeeze_excite/Relu\n",
      "expanded_conv_7/squeeze_excite/Conv_1\n",
      "tf.math.add_16\n",
      "re_lu_21\n",
      "tf.math.multiply_16\n",
      "expanded_conv_7/squeeze_excite/Mul\n",
      "expanded_conv_7/project\n",
      "expanded_conv_7/project/BatchNorm\n",
      "expanded_conv_7/Add\n",
      "expanded_conv_8/expand\n",
      "expanded_conv_8/expand/BatchNorm\n",
      "tf.math.add_17\n",
      "re_lu_22\n",
      "tf.math.multiply_17\n",
      "multiply_11\n",
      "expanded_conv_8/depthwise/pad\n",
      "expanded_conv_8/depthwise\n",
      "expanded_conv_8/depthwise/BatchNorm\n",
      "tf.math.add_18\n",
      "re_lu_23\n",
      "tf.math.multiply_18\n",
      "multiply_12\n",
      "expanded_conv_8/squeeze_excite/AvgPool\n",
      "expanded_conv_8/squeeze_excite/Conv\n",
      "expanded_conv_8/squeeze_excite/Relu\n",
      "expanded_conv_8/squeeze_excite/Conv_1\n",
      "tf.math.add_19\n",
      "re_lu_24\n",
      "tf.math.multiply_19\n",
      "expanded_conv_8/squeeze_excite/Mul\n",
      "expanded_conv_8/project\n",
      "expanded_conv_8/project/BatchNorm\n",
      "expanded_conv_9/expand\n",
      "expanded_conv_9/expand/BatchNorm\n",
      "tf.math.add_20\n",
      "re_lu_25\n",
      "tf.math.multiply_20\n",
      "multiply_13\n",
      "expanded_conv_9/depthwise\n",
      "expanded_conv_9/depthwise/BatchNorm\n",
      "tf.math.add_21\n",
      "re_lu_26\n",
      "tf.math.multiply_21\n",
      "multiply_14\n",
      "expanded_conv_9/squeeze_excite/AvgPool\n",
      "expanded_conv_9/squeeze_excite/Conv\n",
      "expanded_conv_9/squeeze_excite/Relu\n",
      "expanded_conv_9/squeeze_excite/Conv_1\n",
      "tf.math.add_22\n",
      "re_lu_27\n",
      "tf.math.multiply_22\n",
      "expanded_conv_9/squeeze_excite/Mul\n",
      "expanded_conv_9/project\n",
      "expanded_conv_9/project/BatchNorm\n",
      "expanded_conv_9/Add\n",
      "expanded_conv_10/expand\n",
      "expanded_conv_10/expand/BatchNorm\n",
      "tf.math.add_23\n",
      "re_lu_28\n",
      "tf.math.multiply_23\n",
      "multiply_15\n",
      "expanded_conv_10/depthwise\n",
      "expanded_conv_10/depthwise/BatchNorm\n",
      "tf.math.add_24\n",
      "re_lu_29\n",
      "tf.math.multiply_24\n",
      "multiply_16\n",
      "expanded_conv_10/squeeze_excite/AvgPool\n",
      "expanded_conv_10/squeeze_excite/Conv\n",
      "expanded_conv_10/squeeze_excite/Relu\n",
      "expanded_conv_10/squeeze_excite/Conv_1\n",
      "tf.math.add_25\n",
      "re_lu_30\n",
      "tf.math.multiply_25\n",
      "expanded_conv_10/squeeze_excite/Mul\n",
      "expanded_conv_10/project\n",
      "expanded_conv_10/project/BatchNorm\n",
      "expanded_conv_10/Add\n",
      "Conv_1\n",
      "Conv_1/BatchNorm\n",
      "tf.math.add_26\n",
      "re_lu_31\n",
      "tf.math.multiply_26\n",
      "multiply_17\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV3Small(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    print(layer.name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:50:15.173065663Z",
     "start_time": "2024-03-23T15:50:14.416989571Z"
    }
   },
   "id": "50b9be6fe8e66d95",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.src import regularizers\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3), name=\"input_layer\")\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "outputs = layers.Dense(len(bird_classes), activation='softmax', dtype=tf.float32, kernel_regularizer=regularizers.l2(0.005))(x)\n",
    "\n",
    "model1 = tf.keras.Model(inputs, outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:50:15.404783611Z",
     "start_time": "2024-03-23T15:50:15.177816972Z"
    }
   },
   "id": "3dec416dcefcbe82",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " MobilenetV3small (Function  (None, 7, 7, 576)         939120    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 576)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              590848    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 167)               21543     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3635095 (13.87 MB)\n",
      "Trainable params: 2695975 (10.28 MB)\n",
      "Non-trainable params: 939120 (3.58 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:50:15.455218974Z",
     "start_time": "2024-03-23T15:50:15.406023851Z"
    }
   },
   "id": "ac06abe1f3451faa",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 11:50:17.377980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-03-23 11:50:17.430280: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-23 11:50:18.119762: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x74ca68003500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-23 11:50:18.119786: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-03-23 11:50:18.125285: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-23 11:50:18.192674: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564/564 [==============================] - ETA: 0s - loss: 4.7542 - accuracy: 0.0444\n",
      "Epoch 1: val_loss improved from inf to 3.71443, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 15s 21ms/step - loss: 4.7542 - accuracy: 0.0444 - val_loss: 3.7144 - val_accuracy: 0.1001\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thefilthysalad/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560/564 [============================>.] - ETA: 0s - loss: 3.5118 - accuracy: 0.1108\n",
      "Epoch 2: val_loss improved from 3.71443 to 3.05981, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 3.5092 - accuracy: 0.1111 - val_loss: 3.0598 - val_accuracy: 0.1301\n",
      "Epoch 3/10\n",
      "561/564 [============================>.] - ETA: 0s - loss: 2.9524 - accuracy: 0.1706\n",
      "Epoch 3: val_loss improved from 3.05981 to 2.66200, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 2.9512 - accuracy: 0.1706 - val_loss: 2.6620 - val_accuracy: 0.2118\n",
      "Epoch 4/10\n",
      "562/564 [============================>.] - ETA: 0s - loss: 2.5559 - accuracy: 0.2406\n",
      "Epoch 4: val_loss improved from 2.66200 to 2.44850, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 2.5558 - accuracy: 0.2405 - val_loss: 2.4485 - val_accuracy: 0.2771\n",
      "Epoch 5/10\n",
      "562/564 [============================>.] - ETA: 0s - loss: 2.2858 - accuracy: 0.2922\n",
      "Epoch 5: val_loss improved from 2.44850 to 2.14514, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 2.2854 - accuracy: 0.2921 - val_loss: 2.1451 - val_accuracy: 0.3007\n",
      "Epoch 6/10\n",
      "561/564 [============================>.] - ETA: 0s - loss: 2.0818 - accuracy: 0.3458\n",
      "Epoch 6: val_loss improved from 2.14514 to 1.71723, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 2.0810 - accuracy: 0.3458 - val_loss: 1.7172 - val_accuracy: 0.4805\n",
      "Epoch 7/10\n",
      "564/564 [==============================] - ETA: 0s - loss: 1.8895 - accuracy: 0.4034\n",
      "Epoch 7: val_loss improved from 1.71723 to 1.63202, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 1.8895 - accuracy: 0.4034 - val_loss: 1.6320 - val_accuracy: 0.4655\n",
      "Epoch 8/10\n",
      "561/564 [============================>.] - ETA: 0s - loss: 1.6990 - accuracy: 0.4663\n",
      "Epoch 8: val_loss improved from 1.63202 to 1.32422, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 1.6988 - accuracy: 0.4663 - val_loss: 1.3242 - val_accuracy: 0.5884\n",
      "Epoch 9/10\n",
      "563/564 [============================>.] - ETA: 0s - loss: 1.5388 - accuracy: 0.5234\n",
      "Epoch 9: val_loss improved from 1.32422 to 1.22979, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 1.5388 - accuracy: 0.5235 - val_loss: 1.2298 - val_accuracy: 0.6352\n",
      "Epoch 10/10\n",
      "560/564 [============================>.] - ETA: 0s - loss: 1.4074 - accuracy: 0.5705\n",
      "Epoch 10: val_loss improved from 1.22979 to 1.09985, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 1.4089 - accuracy: 0.5705 - val_loss: 1.0999 - val_accuracy: 0.6576\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "                           optimizer=Adam(),\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='Best_models/best_mobilenetv3small.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "history_eff_b0 = model1.fit(train_dataset,\n",
    "                                        validation_data=validation_dataset,\n",
    "                                        epochs=10,\n",
    "                                        verbose=1,\n",
    "                                        callbacks=[checkpointer]) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:52:07.737977769Z",
     "start_time": "2024-03-23T15:50:15.454885711Z"
    }
   },
   "id": "d36b50212b34becf",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "for layer in base_model.layers[-100:]:\n",
    "    layer.trainable = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:52:07.742091696Z",
     "start_time": "2024-03-23T15:52:07.740578675Z"
    }
   },
   "id": "b18fc932dbae1cc2",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "rescaling False\n",
      "Conv False\n",
      "Conv/BatchNorm False\n",
      "tf.math.add False\n",
      "re_lu False\n",
      "tf.math.multiply False\n",
      "multiply False\n",
      "expanded_conv/depthwise/pad False\n",
      "expanded_conv/depthwise False\n",
      "expanded_conv/depthwise/BatchNorm False\n",
      "re_lu_1 False\n",
      "expanded_conv/squeeze_excite/AvgPool False\n",
      "expanded_conv/squeeze_excite/Conv False\n",
      "expanded_conv/squeeze_excite/Relu False\n",
      "expanded_conv/squeeze_excite/Conv_1 False\n",
      "tf.math.add_1 False\n",
      "re_lu_2 False\n",
      "tf.math.multiply_1 False\n",
      "expanded_conv/squeeze_excite/Mul False\n",
      "expanded_conv/project False\n",
      "expanded_conv/project/BatchNorm False\n",
      "expanded_conv_1/expand False\n",
      "expanded_conv_1/expand/BatchNorm False\n",
      "re_lu_3 False\n",
      "expanded_conv_1/depthwise/pad False\n",
      "expanded_conv_1/depthwise False\n",
      "expanded_conv_1/depthwise/BatchNorm False\n",
      "re_lu_4 False\n",
      "expanded_conv_1/project False\n",
      "expanded_conv_1/project/BatchNorm False\n",
      "expanded_conv_2/expand False\n",
      "expanded_conv_2/expand/BatchNorm False\n",
      "re_lu_5 False\n",
      "expanded_conv_2/depthwise False\n",
      "expanded_conv_2/depthwise/BatchNorm False\n",
      "re_lu_6 False\n",
      "expanded_conv_2/project False\n",
      "expanded_conv_2/project/BatchNorm False\n",
      "expanded_conv_2/Add False\n",
      "expanded_conv_3/expand False\n",
      "expanded_conv_3/expand/BatchNorm False\n",
      "tf.math.add_2 False\n",
      "re_lu_7 False\n",
      "tf.math.multiply_2 False\n",
      "multiply_1 False\n",
      "expanded_conv_3/depthwise/pad False\n",
      "expanded_conv_3/depthwise False\n",
      "expanded_conv_3/depthwise/BatchNorm False\n",
      "tf.math.add_3 False\n",
      "re_lu_8 False\n",
      "tf.math.multiply_3 False\n",
      "multiply_2 False\n",
      "expanded_conv_3/squeeze_excite/AvgPool False\n",
      "expanded_conv_3/squeeze_excite/Conv False\n",
      "expanded_conv_3/squeeze_excite/Relu False\n",
      "expanded_conv_3/squeeze_excite/Conv_1 False\n",
      "tf.math.add_4 False\n",
      "re_lu_9 False\n",
      "tf.math.multiply_4 False\n",
      "expanded_conv_3/squeeze_excite/Mul False\n",
      "expanded_conv_3/project False\n",
      "expanded_conv_3/project/BatchNorm False\n",
      "expanded_conv_4/expand False\n",
      "expanded_conv_4/expand/BatchNorm False\n",
      "tf.math.add_5 False\n",
      "re_lu_10 False\n",
      "tf.math.multiply_5 False\n",
      "multiply_3 False\n",
      "expanded_conv_4/depthwise False\n",
      "expanded_conv_4/depthwise/BatchNorm False\n",
      "tf.math.add_6 False\n",
      "re_lu_11 False\n",
      "tf.math.multiply_6 False\n",
      "multiply_4 False\n",
      "expanded_conv_4/squeeze_excite/AvgPool False\n",
      "expanded_conv_4/squeeze_excite/Conv False\n",
      "expanded_conv_4/squeeze_excite/Relu False\n",
      "expanded_conv_4/squeeze_excite/Conv_1 False\n",
      "tf.math.add_7 False\n",
      "re_lu_12 False\n",
      "tf.math.multiply_7 False\n",
      "expanded_conv_4/squeeze_excite/Mul False\n",
      "expanded_conv_4/project False\n",
      "expanded_conv_4/project/BatchNorm False\n",
      "expanded_conv_4/Add False\n",
      "expanded_conv_5/expand False\n",
      "expanded_conv_5/expand/BatchNorm False\n",
      "tf.math.add_8 False\n",
      "re_lu_13 False\n",
      "tf.math.multiply_8 False\n",
      "multiply_5 False\n",
      "expanded_conv_5/depthwise False\n",
      "expanded_conv_5/depthwise/BatchNorm False\n",
      "tf.math.add_9 False\n",
      "re_lu_14 False\n",
      "tf.math.multiply_9 False\n",
      "multiply_6 False\n",
      "expanded_conv_5/squeeze_excite/AvgPool False\n",
      "expanded_conv_5/squeeze_excite/Conv False\n",
      "expanded_conv_5/squeeze_excite/Relu False\n",
      "expanded_conv_5/squeeze_excite/Conv_1 False\n",
      "tf.math.add_10 False\n",
      "re_lu_15 False\n",
      "tf.math.multiply_10 False\n",
      "expanded_conv_5/squeeze_excite/Mul False\n",
      "expanded_conv_5/project False\n",
      "expanded_conv_5/project/BatchNorm False\n",
      "expanded_conv_5/Add False\n",
      "expanded_conv_6/expand False\n",
      "expanded_conv_6/expand/BatchNorm False\n",
      "tf.math.add_11 False\n",
      "re_lu_16 False\n",
      "tf.math.multiply_11 False\n",
      "multiply_7 False\n",
      "expanded_conv_6/depthwise False\n",
      "expanded_conv_6/depthwise/BatchNorm False\n",
      "tf.math.add_12 False\n",
      "re_lu_17 False\n",
      "tf.math.multiply_12 False\n",
      "multiply_8 False\n",
      "expanded_conv_6/squeeze_excite/AvgPool False\n",
      "expanded_conv_6/squeeze_excite/Conv False\n",
      "expanded_conv_6/squeeze_excite/Relu False\n",
      "expanded_conv_6/squeeze_excite/Conv_1 False\n",
      "tf.math.add_13 False\n",
      "re_lu_18 False\n",
      "tf.math.multiply_13 False\n",
      "expanded_conv_6/squeeze_excite/Mul False\n",
      "expanded_conv_6/project True\n",
      "expanded_conv_6/project/BatchNorm True\n",
      "expanded_conv_7/expand True\n",
      "expanded_conv_7/expand/BatchNorm True\n",
      "tf.math.add_14 True\n",
      "re_lu_19 True\n",
      "tf.math.multiply_14 True\n",
      "multiply_9 True\n",
      "expanded_conv_7/depthwise True\n",
      "expanded_conv_7/depthwise/BatchNorm True\n",
      "tf.math.add_15 True\n",
      "re_lu_20 True\n",
      "tf.math.multiply_15 True\n",
      "multiply_10 True\n",
      "expanded_conv_7/squeeze_excite/AvgPool True\n",
      "expanded_conv_7/squeeze_excite/Conv True\n",
      "expanded_conv_7/squeeze_excite/Relu True\n",
      "expanded_conv_7/squeeze_excite/Conv_1 True\n",
      "tf.math.add_16 True\n",
      "re_lu_21 True\n",
      "tf.math.multiply_16 True\n",
      "expanded_conv_7/squeeze_excite/Mul True\n",
      "expanded_conv_7/project True\n",
      "expanded_conv_7/project/BatchNorm True\n",
      "expanded_conv_7/Add True\n",
      "expanded_conv_8/expand True\n",
      "expanded_conv_8/expand/BatchNorm True\n",
      "tf.math.add_17 True\n",
      "re_lu_22 True\n",
      "tf.math.multiply_17 True\n",
      "multiply_11 True\n",
      "expanded_conv_8/depthwise/pad True\n",
      "expanded_conv_8/depthwise True\n",
      "expanded_conv_8/depthwise/BatchNorm True\n",
      "tf.math.add_18 True\n",
      "re_lu_23 True\n",
      "tf.math.multiply_18 True\n",
      "multiply_12 True\n",
      "expanded_conv_8/squeeze_excite/AvgPool True\n",
      "expanded_conv_8/squeeze_excite/Conv True\n",
      "expanded_conv_8/squeeze_excite/Relu True\n",
      "expanded_conv_8/squeeze_excite/Conv_1 True\n",
      "tf.math.add_19 True\n",
      "re_lu_24 True\n",
      "tf.math.multiply_19 True\n",
      "expanded_conv_8/squeeze_excite/Mul True\n",
      "expanded_conv_8/project True\n",
      "expanded_conv_8/project/BatchNorm True\n",
      "expanded_conv_9/expand True\n",
      "expanded_conv_9/expand/BatchNorm True\n",
      "tf.math.add_20 True\n",
      "re_lu_25 True\n",
      "tf.math.multiply_20 True\n",
      "multiply_13 True\n",
      "expanded_conv_9/depthwise True\n",
      "expanded_conv_9/depthwise/BatchNorm True\n",
      "tf.math.add_21 True\n",
      "re_lu_26 True\n",
      "tf.math.multiply_21 True\n",
      "multiply_14 True\n",
      "expanded_conv_9/squeeze_excite/AvgPool True\n",
      "expanded_conv_9/squeeze_excite/Conv True\n",
      "expanded_conv_9/squeeze_excite/Relu True\n",
      "expanded_conv_9/squeeze_excite/Conv_1 True\n",
      "tf.math.add_22 True\n",
      "re_lu_27 True\n",
      "tf.math.multiply_22 True\n",
      "expanded_conv_9/squeeze_excite/Mul True\n",
      "expanded_conv_9/project True\n",
      "expanded_conv_9/project/BatchNorm True\n",
      "expanded_conv_9/Add True\n",
      "expanded_conv_10/expand True\n",
      "expanded_conv_10/expand/BatchNorm True\n",
      "tf.math.add_23 True\n",
      "re_lu_28 True\n",
      "tf.math.multiply_23 True\n",
      "multiply_15 True\n",
      "expanded_conv_10/depthwise True\n",
      "expanded_conv_10/depthwise/BatchNorm True\n",
      "tf.math.add_24 True\n",
      "re_lu_29 True\n",
      "tf.math.multiply_24 True\n",
      "multiply_16 True\n",
      "expanded_conv_10/squeeze_excite/AvgPool True\n",
      "expanded_conv_10/squeeze_excite/Conv True\n",
      "expanded_conv_10/squeeze_excite/Relu True\n",
      "expanded_conv_10/squeeze_excite/Conv_1 True\n",
      "tf.math.add_25 True\n",
      "re_lu_30 True\n",
      "tf.math.multiply_25 True\n",
      "expanded_conv_10/squeeze_excite/Mul True\n",
      "expanded_conv_10/project True\n",
      "expanded_conv_10/project/BatchNorm True\n",
      "expanded_conv_10/Add True\n",
      "Conv_1 True\n",
      "Conv_1/BatchNorm True\n",
      "tf.math.add_26 True\n",
      "re_lu_31 True\n",
      "tf.math.multiply_26 True\n",
      "multiply_17 True\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:52:07.748744253Z",
     "start_time": "2024-03-23T15:52:07.743180704Z"
    }
   },
   "id": "396cc7ef6dbc7bae",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "562/564 [============================>.] - ETA: 0s - loss: 1.2782 - accuracy: 0.6141\n",
      "Epoch 11: val_loss improved from 1.09985 to 0.93692, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 14s 20ms/step - loss: 1.2779 - accuracy: 0.6142 - val_loss: 0.9369 - val_accuracy: 0.7268\n",
      "Epoch 12/25\n",
      "560/564 [============================>.] - ETA: 0s - loss: 1.2054 - accuracy: 0.6525\n",
      "Epoch 12: val_loss did not improve from 0.93692\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 1.2058 - accuracy: 0.6524 - val_loss: 1.0571 - val_accuracy: 0.7084\n",
      "Epoch 13/25\n",
      "560/564 [============================>.] - ETA: 0s - loss: 1.1390 - accuracy: 0.6708\n",
      "Epoch 13: val_loss improved from 0.93692 to 0.89186, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 1.1388 - accuracy: 0.6710 - val_loss: 0.8919 - val_accuracy: 0.7374\n",
      "Epoch 14/25\n",
      "564/564 [==============================] - ETA: 0s - loss: 1.0588 - accuracy: 0.6965\n",
      "Epoch 14: val_loss did not improve from 0.89186\n",
      "564/564 [==============================] - 10s 18ms/step - loss: 1.0588 - accuracy: 0.6965 - val_loss: 0.9805 - val_accuracy: 0.7629\n",
      "Epoch 15/25\n",
      "564/564 [==============================] - ETA: 0s - loss: 1.0248 - accuracy: 0.7163\n",
      "Epoch 15: val_loss did not improve from 0.89186\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 1.0248 - accuracy: 0.7163 - val_loss: 0.9386 - val_accuracy: 0.7447\n",
      "Epoch 16/25\n",
      "562/564 [============================>.] - ETA: 0s - loss: 0.9668 - accuracy: 0.7363\n",
      "Epoch 16: val_loss improved from 0.89186 to 0.80969, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 0.9662 - accuracy: 0.7365 - val_loss: 0.8097 - val_accuracy: 0.7829\n",
      "Epoch 17/25\n",
      "561/564 [============================>.] - ETA: 0s - loss: 0.9139 - accuracy: 0.7523\n",
      "Epoch 17: val_loss improved from 0.80969 to 0.80166, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 0.9139 - accuracy: 0.7522 - val_loss: 0.8017 - val_accuracy: 0.7770\n",
      "Epoch 18/25\n",
      "562/564 [============================>.] - ETA: 0s - loss: 0.8699 - accuracy: 0.7686\n",
      "Epoch 18: val_loss improved from 0.80166 to 0.77836, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 0.8704 - accuracy: 0.7684 - val_loss: 0.7784 - val_accuracy: 0.7799\n",
      "Epoch 19/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 0.8342 - accuracy: 0.7779\n",
      "Epoch 19: val_loss improved from 0.77836 to 0.71057, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 20ms/step - loss: 0.8343 - accuracy: 0.7779 - val_loss: 0.7106 - val_accuracy: 0.8332\n",
      "Epoch 20/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 0.8287 - accuracy: 0.7853\n",
      "Epoch 20: val_loss did not improve from 0.71057\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 0.8285 - accuracy: 0.7854 - val_loss: 0.7283 - val_accuracy: 0.8027\n",
      "Epoch 21/25\n",
      "560/564 [============================>.] - ETA: 0s - loss: 0.7818 - accuracy: 0.7951\n",
      "Epoch 21: val_loss did not improve from 0.71057\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 0.7823 - accuracy: 0.7949 - val_loss: 0.7409 - val_accuracy: 0.8020\n",
      "Epoch 22/25\n",
      "562/564 [============================>.] - ETA: 0s - loss: 0.7725 - accuracy: 0.8008\n",
      "Epoch 22: val_loss did not improve from 0.71057\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 0.7722 - accuracy: 0.8008 - val_loss: 0.7814 - val_accuracy: 0.8229\n",
      "Epoch 23/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 0.7655 - accuracy: 0.8088\n",
      "Epoch 23: val_loss did not improve from 0.71057\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 0.7655 - accuracy: 0.8088 - val_loss: 0.7731 - val_accuracy: 0.8271\n",
      "Epoch 24/25\n",
      "561/564 [============================>.] - ETA: 0s - loss: 0.7077 - accuracy: 0.8196\n",
      "Epoch 24: val_loss improved from 0.71057 to 0.66014, saving model to Best_models/best_mobilenetv3small.hdf5\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 0.7074 - accuracy: 0.8197 - val_loss: 0.6601 - val_accuracy: 0.8361\n",
      "Epoch 25/25\n",
      "561/564 [============================>.] - ETA: 0s - loss: 0.7298 - accuracy: 0.8202\n",
      "Epoch 25: val_loss did not improve from 0.66014\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 0.7303 - accuracy: 0.8202 - val_loss: 0.7970 - val_accuracy: 0.8130\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x74cb281248e0>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "                           optimizer=Adam(),\n",
    "                           metrics=['accuracy'])\n",
    "start_epoch = 10\n",
    "\n",
    "model1.fit(train_dataset,\n",
    "                                        validation_data=validation_dataset,\n",
    "                                        epochs=start_epoch+15,\n",
    "                                        initial_epoch=start_epoch, \n",
    "                                        verbose=1,\n",
    "                                        callbacks=[checkpointer]) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:54:52.128021601Z",
     "start_time": "2024-03-23T15:52:07.747626522Z"
    }
   },
   "id": "203e49fb2dead93f",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "229"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_model.layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:54:52.131762850Z",
     "start_time": "2024-03-23T15:54:52.129090861Z"
    }
   },
   "id": "6ecf65f6cb6daf4e",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "for layer in base_model.layers[-150:]:\n",
    "    layer.trainable = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:54:52.144793039Z",
     "start_time": "2024-03-23T15:54:52.131917991Z"
    }
   },
   "id": "c9c1648ec5fea6af",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/130\n",
      "561/564 [============================>.] - ETA: 0s - loss: 0.2330 - accuracy: 0.9329\n",
      "Epoch 116: val_loss did not improve from 0.34074\n",
      "564/564 [==============================] - 13s 19ms/step - loss: 0.2336 - accuracy: 0.9326 - val_loss: 0.4051 - val_accuracy: 0.9201\n",
      "Epoch 117/130\n",
      "559/564 [============================>.] - ETA: 0s - loss: 0.2003 - accuracy: 0.9349\n",
      "Epoch 117: val_loss did not improve from 0.34074\n",
      "564/564 [==============================] - 10s 18ms/step - loss: 0.2003 - accuracy: 0.9347 - val_loss: 0.4064 - val_accuracy: 0.9305\n",
      "Epoch 118/130\n",
      "563/564 [============================>.] - ETA: 0s - loss: 0.1878 - accuracy: 0.9363\n",
      "Epoch 118: val_loss did not improve from 0.34074\n",
      "564/564 [==============================] - 10s 18ms/step - loss: 0.1878 - accuracy: 0.9362 - val_loss: 0.4104 - val_accuracy: 0.9113\n",
      "Epoch 119/130\n",
      "560/564 [============================>.] - ETA: 0s - loss: 0.1797 - accuracy: 0.9368\n",
      "Epoch 119: val_loss did not improve from 0.34074\n",
      "564/564 [==============================] - 10s 18ms/step - loss: 0.1798 - accuracy: 0.9366 - val_loss: 0.4092 - val_accuracy: 0.9138\n",
      "Epoch 120/130\n",
      "563/564 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 0.9393\n",
      "Epoch 120: val_loss did not improve from 0.34074\n",
      "564/564 [==============================] - 10s 18ms/step - loss: 0.1747 - accuracy: 0.9393 - val_loss: 0.4070 - val_accuracy: 0.9095\n",
      "Epoch 121/130\n",
      "561/564 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9366\n",
      "Epoch 121: val_loss did not improve from 0.34074\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 0.1721 - accuracy: 0.9365 - val_loss: 0.3849 - val_accuracy: 0.9228\n",
      "Epoch 122/130\n",
      "562/564 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9374\n",
      "Epoch 122: val_loss did not improve from 0.34074\n",
      "564/564 [==============================] - 10s 18ms/step - loss: 0.1666 - accuracy: 0.9375 - val_loss: 0.3959 - val_accuracy: 0.9221\n",
      "Epoch 123/130\n",
      "561/564 [============================>.] - ETA: 0s - loss: 0.1612 - accuracy: 0.9389\n",
      "Epoch 123: val_loss did not improve from 0.34074\n",
      "564/564 [==============================] - 10s 18ms/step - loss: 0.1613 - accuracy: 0.9389 - val_loss: 0.3928 - val_accuracy: 0.9226\n",
      "Epoch 124/130\n",
      "560/564 [============================>.] - ETA: 0s - loss: 0.1591 - accuracy: 0.9366\n",
      "Epoch 124: val_loss did not improve from 0.34074\n",
      "564/564 [==============================] - 10s 18ms/step - loss: 0.1590 - accuracy: 0.9366 - val_loss: 0.3737 - val_accuracy: 0.9221\n",
      "Epoch 125/130\n",
      "563/564 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9377\n",
      "Epoch 125: val_loss did not improve from 0.34074\n",
      "564/564 [==============================] - 11s 19ms/step - loss: 0.1551 - accuracy: 0.9377 - val_loss: 0.3923 - val_accuracy: 0.9187\n",
      "Epoch 126/130\n",
      "564/564 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.9355"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m model1\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      2\u001B[0m                            optimizer\u001B[38;5;241m=\u001B[39mAdam(\u001B[38;5;241m0.0001\u001B[39m, beta_1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m),\n\u001B[1;32m      3\u001B[0m                            metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      4\u001B[0m start_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m115\u001B[39m\n\u001B[0;32m----> 6\u001B[0m \u001B[43mmodel1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m                                        \u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                                        \u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_epoch\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpointer\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1832\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1816\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[1;32m   1818\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[1;32m   1819\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1830\u001B[0m         pss_evaluation_shards\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pss_evaluation_shards,\n\u001B[1;32m   1831\u001B[0m     )\n\u001B[0;32m-> 1832\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1833\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1834\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1835\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1836\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1837\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1838\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1839\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1840\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1841\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1842\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1843\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1844\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1845\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   1846\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m   1847\u001B[0m }\n\u001B[1;32m   1848\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:2272\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   2268\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   2269\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   2270\u001B[0m             ):\n\u001B[1;32m   2271\u001B[0m                 callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m-> 2272\u001B[0m                 logs \u001B[38;5;241m=\u001B[39m \u001B[43mtest_function_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2273\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2274\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdata_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2275\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2276\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pss_evaluation_shards\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2277\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2279\u001B[0m logs \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39msync_to_numpy_or_python_type(logs)\n\u001B[1;32m   2280\u001B[0m \u001B[38;5;66;03m# Override with model metrics instead of last step logs\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:4079\u001B[0m, in \u001B[0;36m_TestFunction.run_step\u001B[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001B[0m\n\u001B[1;32m   4078\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001B[0;32m-> 4079\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4080\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   4081\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:876\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    873\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    874\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 876\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    880\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    881\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1266\u001B[0m     args,\n\u001B[1;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1268\u001B[0m     executing_eagerly)\n\u001B[1;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    262\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1494\u001B[0m   )\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[1;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[1;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[1;32m     59\u001B[0m   ]\n\u001B[0;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "                           optimizer=Adam(0.0001, beta_1=0.8),\n",
    "                           metrics=['accuracy'])\n",
    "start_epoch = 115\n",
    "\n",
    "model1.fit(train_dataset,\n",
    "                                        \n",
    "                                        validation_data=validation_dataset,\n",
    "                                        \n",
    "                                        epochs=start_epoch+15,\n",
    "                                        initial_epoch=start_epoch, \n",
    "                                        verbose=1,\n",
    "                                        callbacks=[checkpointer]) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T16:16:06.246270103Z",
     "start_time": "2024-03-23T16:14:13.083985930Z"
    }
   },
   "id": "686cc96cfff8e778",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "loaded = tf.keras.models.load_model(\"Best_models/best_mobilenetv3small.hdf5\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T16:16:21.930792034Z",
     "start_time": "2024-03-23T16:16:20.973952002Z"
    }
   },
   "id": "8eb1c67185cf1e80",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 4s 12ms/step - loss: 0.5539 - accuracy: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.5539168119430542, 0.8965786099433899]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded.evaluate(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T16:17:23.076338541Z",
     "start_time": "2024-03-23T16:17:18.598096307Z"
    }
   },
   "id": "d2074b3b5fce0214",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Best_models/best_mobilenet_small_89.65/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Best_models/best_mobilenet_small_89.65/assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(loaded, \"Best_models/best_mobilenet_small_89.65\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T16:18:01.275053662Z",
     "start_time": "2024-03-23T16:17:54.679208540Z"
    }
   },
   "id": "1bc971b4708d2444",
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
