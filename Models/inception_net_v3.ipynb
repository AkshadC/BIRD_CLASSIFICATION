{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:37:52.214893976Z",
     "start_time": "2024-03-23T17:37:50.313811787Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 13:37:50.447677: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-23 13:37:50.471990: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-23 13:37:50.472016: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-23 13:37:50.472042: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-23 13:37:50.477664: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-23 13:37:51.128910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 13:37:52.184972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 13:37:52.207409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 13:37:52.207625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 13:37:52.207946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import utils\n",
    "from tensorflow.keras import mixed_precision\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data_path = \"BIRDS1_split/train\"\n",
    "test_data_path = \"BIRDS1_split/test\"\n",
    "IMG_HEIGHT, IMG_WIDTH = 299, 299\n",
    "BATCH_SIZE = 32\n",
    "bird_classes = sorted(os.listdir(train_data_path))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:37:52.215202605Z",
     "start_time": "2024-03-23T17:37:52.211920853Z"
    }
   },
   "id": "6ef16eed851f94c6",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25744 files belonging to 167 classes.\n",
      "Using 18021 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 13:37:52.753778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 13:37:52.754080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 13:37:52.754244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 13:37:52.826417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 13:37:52.826691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 13:37:52.826931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-23 13:37:52.827123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6075 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-03-23 13:37:53.001830: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25744 files belonging to 167 classes.\n",
      "Using 7723 files for validation.\n",
      "Found 11545 files belonging to 167 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    shuffle=False,\n",
    "    seed=123,\n",
    "\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:37:54.292600870Z",
     "start_time": "2024-03-23T17:37:52.214578665Z"
    }
   },
   "id": "727dfbfe4c00fe25",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
    "train_dataset = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "validation_dataset = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (preprocess_input(x), y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:37:54.321455146Z",
     "start_time": "2024-03-23T17:37:54.292364978Z"
    }
   },
   "id": "10dd6962d0bf3fe8",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "conv2d\n",
      "batch_normalization\n",
      "activation\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "activation_1\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "activation_2\n",
      "max_pooling2d\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "activation_3\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "activation_4\n",
      "max_pooling2d_1\n",
      "conv2d_8\n",
      "batch_normalization_8\n",
      "activation_8\n",
      "conv2d_6\n",
      "conv2d_9\n",
      "batch_normalization_6\n",
      "batch_normalization_9\n",
      "activation_6\n",
      "activation_9\n",
      "average_pooling2d\n",
      "conv2d_5\n",
      "conv2d_7\n",
      "conv2d_10\n",
      "conv2d_11\n",
      "batch_normalization_5\n",
      "batch_normalization_7\n",
      "batch_normalization_10\n",
      "batch_normalization_11\n",
      "activation_5\n",
      "activation_7\n",
      "activation_10\n",
      "activation_11\n",
      "mixed0\n",
      "conv2d_15\n",
      "batch_normalization_15\n",
      "activation_15\n",
      "conv2d_13\n",
      "conv2d_16\n",
      "batch_normalization_13\n",
      "batch_normalization_16\n",
      "activation_13\n",
      "activation_16\n",
      "average_pooling2d_1\n",
      "conv2d_12\n",
      "conv2d_14\n",
      "conv2d_17\n",
      "conv2d_18\n",
      "batch_normalization_12\n",
      "batch_normalization_14\n",
      "batch_normalization_17\n",
      "batch_normalization_18\n",
      "activation_12\n",
      "activation_14\n",
      "activation_17\n",
      "activation_18\n",
      "mixed1\n",
      "conv2d_22\n",
      "batch_normalization_22\n",
      "activation_22\n",
      "conv2d_20\n",
      "conv2d_23\n",
      "batch_normalization_20\n",
      "batch_normalization_23\n",
      "activation_20\n",
      "activation_23\n",
      "average_pooling2d_2\n",
      "conv2d_19\n",
      "conv2d_21\n",
      "conv2d_24\n",
      "conv2d_25\n",
      "batch_normalization_19\n",
      "batch_normalization_21\n",
      "batch_normalization_24\n",
      "batch_normalization_25\n",
      "activation_19\n",
      "activation_21\n",
      "activation_24\n",
      "activation_25\n",
      "mixed2\n",
      "conv2d_27\n",
      "batch_normalization_27\n",
      "activation_27\n",
      "conv2d_28\n",
      "batch_normalization_28\n",
      "activation_28\n",
      "conv2d_26\n",
      "conv2d_29\n",
      "batch_normalization_26\n",
      "batch_normalization_29\n",
      "activation_26\n",
      "activation_29\n",
      "max_pooling2d_2\n",
      "mixed3\n",
      "conv2d_34\n",
      "batch_normalization_34\n",
      "activation_34\n",
      "conv2d_35\n",
      "batch_normalization_35\n",
      "activation_35\n",
      "conv2d_31\n",
      "conv2d_36\n",
      "batch_normalization_31\n",
      "batch_normalization_36\n",
      "activation_31\n",
      "activation_36\n",
      "conv2d_32\n",
      "conv2d_37\n",
      "batch_normalization_32\n",
      "batch_normalization_37\n",
      "activation_32\n",
      "activation_37\n",
      "average_pooling2d_3\n",
      "conv2d_30\n",
      "conv2d_33\n",
      "conv2d_38\n",
      "conv2d_39\n",
      "batch_normalization_30\n",
      "batch_normalization_33\n",
      "batch_normalization_38\n",
      "batch_normalization_39\n",
      "activation_30\n",
      "activation_33\n",
      "activation_38\n",
      "activation_39\n",
      "mixed4\n",
      "conv2d_44\n",
      "batch_normalization_44\n",
      "activation_44\n",
      "conv2d_45\n",
      "batch_normalization_45\n",
      "activation_45\n",
      "conv2d_41\n",
      "conv2d_46\n",
      "batch_normalization_41\n",
      "batch_normalization_46\n",
      "activation_41\n",
      "activation_46\n",
      "conv2d_42\n",
      "conv2d_47\n",
      "batch_normalization_42\n",
      "batch_normalization_47\n",
      "activation_42\n",
      "activation_47\n",
      "average_pooling2d_4\n",
      "conv2d_40\n",
      "conv2d_43\n",
      "conv2d_48\n",
      "conv2d_49\n",
      "batch_normalization_40\n",
      "batch_normalization_43\n",
      "batch_normalization_48\n",
      "batch_normalization_49\n",
      "activation_40\n",
      "activation_43\n",
      "activation_48\n",
      "activation_49\n",
      "mixed5\n",
      "conv2d_54\n",
      "batch_normalization_54\n",
      "activation_54\n",
      "conv2d_55\n",
      "batch_normalization_55\n",
      "activation_55\n",
      "conv2d_51\n",
      "conv2d_56\n",
      "batch_normalization_51\n",
      "batch_normalization_56\n",
      "activation_51\n",
      "activation_56\n",
      "conv2d_52\n",
      "conv2d_57\n",
      "batch_normalization_52\n",
      "batch_normalization_57\n",
      "activation_52\n",
      "activation_57\n",
      "average_pooling2d_5\n",
      "conv2d_50\n",
      "conv2d_53\n",
      "conv2d_58\n",
      "conv2d_59\n",
      "batch_normalization_50\n",
      "batch_normalization_53\n",
      "batch_normalization_58\n",
      "batch_normalization_59\n",
      "activation_50\n",
      "activation_53\n",
      "activation_58\n",
      "activation_59\n",
      "mixed6\n",
      "conv2d_64\n",
      "batch_normalization_64\n",
      "activation_64\n",
      "conv2d_65\n",
      "batch_normalization_65\n",
      "activation_65\n",
      "conv2d_61\n",
      "conv2d_66\n",
      "batch_normalization_61\n",
      "batch_normalization_66\n",
      "activation_61\n",
      "activation_66\n",
      "conv2d_62\n",
      "conv2d_67\n",
      "batch_normalization_62\n",
      "batch_normalization_67\n",
      "activation_62\n",
      "activation_67\n",
      "average_pooling2d_6\n",
      "conv2d_60\n",
      "conv2d_63\n",
      "conv2d_68\n",
      "conv2d_69\n",
      "batch_normalization_60\n",
      "batch_normalization_63\n",
      "batch_normalization_68\n",
      "batch_normalization_69\n",
      "activation_60\n",
      "activation_63\n",
      "activation_68\n",
      "activation_69\n",
      "mixed7\n",
      "conv2d_72\n",
      "batch_normalization_72\n",
      "activation_72\n",
      "conv2d_73\n",
      "batch_normalization_73\n",
      "activation_73\n",
      "conv2d_70\n",
      "conv2d_74\n",
      "batch_normalization_70\n",
      "batch_normalization_74\n",
      "activation_70\n",
      "activation_74\n",
      "conv2d_71\n",
      "conv2d_75\n",
      "batch_normalization_71\n",
      "batch_normalization_75\n",
      "activation_71\n",
      "activation_75\n",
      "max_pooling2d_3\n",
      "mixed8\n",
      "conv2d_80\n",
      "batch_normalization_80\n",
      "activation_80\n",
      "conv2d_77\n",
      "conv2d_81\n",
      "batch_normalization_77\n",
      "batch_normalization_81\n",
      "activation_77\n",
      "activation_81\n",
      "conv2d_78\n",
      "conv2d_79\n",
      "conv2d_82\n",
      "conv2d_83\n",
      "average_pooling2d_7\n",
      "conv2d_76\n",
      "batch_normalization_78\n",
      "batch_normalization_79\n",
      "batch_normalization_82\n",
      "batch_normalization_83\n",
      "conv2d_84\n",
      "batch_normalization_76\n",
      "activation_78\n",
      "activation_79\n",
      "activation_82\n",
      "activation_83\n",
      "batch_normalization_84\n",
      "activation_76\n",
      "mixed9_0\n",
      "concatenate\n",
      "activation_84\n",
      "mixed9\n",
      "conv2d_89\n",
      "batch_normalization_89\n",
      "activation_89\n",
      "conv2d_86\n",
      "conv2d_90\n",
      "batch_normalization_86\n",
      "batch_normalization_90\n",
      "activation_86\n",
      "activation_90\n",
      "conv2d_87\n",
      "conv2d_88\n",
      "conv2d_91\n",
      "conv2d_92\n",
      "average_pooling2d_8\n",
      "conv2d_85\n",
      "batch_normalization_87\n",
      "batch_normalization_88\n",
      "batch_normalization_91\n",
      "batch_normalization_92\n",
      "conv2d_93\n",
      "batch_normalization_85\n",
      "activation_87\n",
      "activation_88\n",
      "activation_91\n",
      "activation_92\n",
      "batch_normalization_93\n",
      "activation_85\n",
      "mixed9_1\n",
      "concatenate_1\n",
      "activation_93\n",
      "mixed10\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    print(layer.name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:37:55.610144166Z",
     "start_time": "2024-03-23T17:37:54.324057756Z"
    }
   },
   "id": "50b9be6fe8e66d95",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.src import regularizers\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3), name=\"input_layer\")\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "outputs = layers.Dense(len(bird_classes), activation='softmax', dtype=tf.float32, kernel_regularizer=regularizers.l2(0.005))(x)\n",
    "\n",
    "model1 = tf.keras.Model(inputs, outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:37:55.948886405Z",
     "start_time": "2024-03-23T17:37:55.610880557Z"
    }
   },
   "id": "3dec416dcefcbe82",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 299, 299, 3)]     0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 167)               10855     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23712775 (90.46 MB)\n",
      "Trainable params: 1909991 (7.29 MB)\n",
      "Non-trainable params: 21802784 (83.17 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:37:55.956414969Z",
     "start_time": "2024-03-23T17:37:55.934365730Z"
    }
   },
   "id": "ac06abe1f3451faa",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=3) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:37:56.002880495Z",
     "start_time": "2024-03-23T17:37:55.955554245Z"
    }
   },
   "id": "e14615154f708d8b",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 13:37:58.855448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2024-03-23 13:37:58.956851: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-23 13:38:00.584230: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6485183e0c90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-23 13:38:00.584252: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-03-23 13:38:00.593217: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-23 13:38:00.662933: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564/564 [==============================] - ETA: 0s - loss: 4.8180 - accuracy: 0.0218\n",
      "Epoch 1: val_loss improved from inf to 4.39201, saving model to Best_models/best_inceptionv3.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thefilthysalad/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564/564 [==============================] - 45s 71ms/step - loss: 4.8180 - accuracy: 0.0218 - val_loss: 4.3920 - val_accuracy: 1.2948e-04 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "563/564 [============================>.] - ETA: 0s - loss: 4.1576 - accuracy: 0.0354\n",
      "Epoch 2: val_loss improved from 4.39201 to 3.88642, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 37s 66ms/step - loss: 4.1576 - accuracy: 0.0354 - val_loss: 3.8864 - val_accuracy: 0.0230 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "563/564 [============================>.] - ETA: 0s - loss: 3.6971 - accuracy: 0.0703\n",
      "Epoch 3: val_loss improved from 3.88642 to 3.47313, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 40s 71ms/step - loss: 3.6970 - accuracy: 0.0703 - val_loss: 3.4731 - val_accuracy: 0.1220 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "564/564 [==============================] - ETA: 0s - loss: 3.3561 - accuracy: 0.1021\n",
      "Epoch 4: val_loss improved from 3.47313 to 3.32065, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 39s 70ms/step - loss: 3.3561 - accuracy: 0.1021 - val_loss: 3.3207 - val_accuracy: 0.0282 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "563/564 [============================>.] - ETA: 0s - loss: 3.1302 - accuracy: 0.1232\n",
      "Epoch 5: val_loss improved from 3.32065 to 3.06688, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 38s 67ms/step - loss: 3.1303 - accuracy: 0.1232 - val_loss: 3.0669 - val_accuracy: 0.1480 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "564/564 [==============================] - ETA: 0s - loss: 2.9973 - accuracy: 0.1429\n",
      "Epoch 6: val_loss improved from 3.06688 to 2.78482, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 37s 65ms/step - loss: 2.9973 - accuracy: 0.1429 - val_loss: 2.7848 - val_accuracy: 0.1666 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "563/564 [============================>.] - ETA: 0s - loss: 2.8614 - accuracy: 0.1667\n",
      "Epoch 7: val_loss improved from 2.78482 to 2.72442, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 37s 66ms/step - loss: 2.8614 - accuracy: 0.1667 - val_loss: 2.7244 - val_accuracy: 0.1795 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "564/564 [==============================] - ETA: 0s - loss: 2.7076 - accuracy: 0.1941\n",
      "Epoch 8: val_loss improved from 2.72442 to 2.53416, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 37s 66ms/step - loss: 2.7076 - accuracy: 0.1941 - val_loss: 2.5342 - val_accuracy: 0.2442 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "564/564 [==============================] - ETA: 0s - loss: 2.6168 - accuracy: 0.2141\n",
      "Epoch 9: val_loss improved from 2.53416 to 2.44267, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 37s 66ms/step - loss: 2.6168 - accuracy: 0.2141 - val_loss: 2.4427 - val_accuracy: 0.2205 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "563/564 [============================>.] - ETA: 0s - loss: 2.4860 - accuracy: 0.2412\n",
      "Epoch 10: val_loss improved from 2.44267 to 2.32850, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 37s 66ms/step - loss: 2.4861 - accuracy: 0.2412 - val_loss: 2.3285 - val_accuracy: 0.2544 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "                           optimizer=Adam(),\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='Best_models/best_inceptionv3.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "history_eff_b0 = model1.fit(train_dataset,  \n",
    "                                        validation_data=validation_dataset,\n",
    "                                        epochs=10,\n",
    "                                        verbose=1,\n",
    "                                        callbacks=[checkpointer, lr_scheduler]) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:44:21.106285275Z",
     "start_time": "2024-03-23T17:37:56.002810494Z"
    }
   },
   "id": "d36b50212b34becf",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:44:21.109229266Z",
     "start_time": "2024-03-23T17:44:21.107994199Z"
    }
   },
   "id": "b18fc932dbae1cc2",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "conv2d False\n",
      "batch_normalization False\n",
      "activation False\n",
      "conv2d_1 False\n",
      "batch_normalization_1 False\n",
      "activation_1 False\n",
      "conv2d_2 False\n",
      "batch_normalization_2 False\n",
      "activation_2 False\n",
      "max_pooling2d False\n",
      "conv2d_3 False\n",
      "batch_normalization_3 False\n",
      "activation_3 False\n",
      "conv2d_4 False\n",
      "batch_normalization_4 False\n",
      "activation_4 False\n",
      "max_pooling2d_1 False\n",
      "conv2d_8 False\n",
      "batch_normalization_8 False\n",
      "activation_8 False\n",
      "conv2d_6 False\n",
      "conv2d_9 False\n",
      "batch_normalization_6 False\n",
      "batch_normalization_9 False\n",
      "activation_6 False\n",
      "activation_9 False\n",
      "average_pooling2d False\n",
      "conv2d_5 False\n",
      "conv2d_7 False\n",
      "conv2d_10 False\n",
      "conv2d_11 False\n",
      "batch_normalization_5 False\n",
      "batch_normalization_7 False\n",
      "batch_normalization_10 False\n",
      "batch_normalization_11 False\n",
      "activation_5 False\n",
      "activation_7 False\n",
      "activation_10 False\n",
      "activation_11 False\n",
      "mixed0 False\n",
      "conv2d_15 False\n",
      "batch_normalization_15 False\n",
      "activation_15 False\n",
      "conv2d_13 False\n",
      "conv2d_16 False\n",
      "batch_normalization_13 False\n",
      "batch_normalization_16 False\n",
      "activation_13 False\n",
      "activation_16 False\n",
      "average_pooling2d_1 False\n",
      "conv2d_12 False\n",
      "conv2d_14 False\n",
      "conv2d_17 False\n",
      "conv2d_18 False\n",
      "batch_normalization_12 False\n",
      "batch_normalization_14 False\n",
      "batch_normalization_17 False\n",
      "batch_normalization_18 False\n",
      "activation_12 False\n",
      "activation_14 False\n",
      "activation_17 False\n",
      "activation_18 False\n",
      "mixed1 False\n",
      "conv2d_22 False\n",
      "batch_normalization_22 False\n",
      "activation_22 False\n",
      "conv2d_20 False\n",
      "conv2d_23 False\n",
      "batch_normalization_20 False\n",
      "batch_normalization_23 False\n",
      "activation_20 False\n",
      "activation_23 False\n",
      "average_pooling2d_2 False\n",
      "conv2d_19 False\n",
      "conv2d_21 False\n",
      "conv2d_24 False\n",
      "conv2d_25 False\n",
      "batch_normalization_19 False\n",
      "batch_normalization_21 False\n",
      "batch_normalization_24 False\n",
      "batch_normalization_25 False\n",
      "activation_19 False\n",
      "activation_21 False\n",
      "activation_24 False\n",
      "activation_25 False\n",
      "mixed2 False\n",
      "conv2d_27 False\n",
      "batch_normalization_27 False\n",
      "activation_27 False\n",
      "conv2d_28 False\n",
      "batch_normalization_28 False\n",
      "activation_28 False\n",
      "conv2d_26 False\n",
      "conv2d_29 False\n",
      "batch_normalization_26 False\n",
      "batch_normalization_29 False\n",
      "activation_26 False\n",
      "activation_29 False\n",
      "max_pooling2d_2 False\n",
      "mixed3 False\n",
      "conv2d_34 False\n",
      "batch_normalization_34 False\n",
      "activation_34 False\n",
      "conv2d_35 False\n",
      "batch_normalization_35 False\n",
      "activation_35 False\n",
      "conv2d_31 False\n",
      "conv2d_36 False\n",
      "batch_normalization_31 False\n",
      "batch_normalization_36 False\n",
      "activation_31 False\n",
      "activation_36 False\n",
      "conv2d_32 False\n",
      "conv2d_37 False\n",
      "batch_normalization_32 False\n",
      "batch_normalization_37 False\n",
      "activation_32 False\n",
      "activation_37 False\n",
      "average_pooling2d_3 False\n",
      "conv2d_30 False\n",
      "conv2d_33 False\n",
      "conv2d_38 False\n",
      "conv2d_39 False\n",
      "batch_normalization_30 False\n",
      "batch_normalization_33 False\n",
      "batch_normalization_38 False\n",
      "batch_normalization_39 False\n",
      "activation_30 False\n",
      "activation_33 False\n",
      "activation_38 False\n",
      "activation_39 False\n",
      "mixed4 False\n",
      "conv2d_44 False\n",
      "batch_normalization_44 False\n",
      "activation_44 False\n",
      "conv2d_45 False\n",
      "batch_normalization_45 False\n",
      "activation_45 False\n",
      "conv2d_41 False\n",
      "conv2d_46 False\n",
      "batch_normalization_41 False\n",
      "batch_normalization_46 False\n",
      "activation_41 False\n",
      "activation_46 False\n",
      "conv2d_42 False\n",
      "conv2d_47 False\n",
      "batch_normalization_42 False\n",
      "batch_normalization_47 False\n",
      "activation_42 False\n",
      "activation_47 False\n",
      "average_pooling2d_4 False\n",
      "conv2d_40 False\n",
      "conv2d_43 False\n",
      "conv2d_48 False\n",
      "conv2d_49 False\n",
      "batch_normalization_40 False\n",
      "batch_normalization_43 False\n",
      "batch_normalization_48 False\n",
      "batch_normalization_49 False\n",
      "activation_40 False\n",
      "activation_43 False\n",
      "activation_48 False\n",
      "activation_49 False\n",
      "mixed5 False\n",
      "conv2d_54 False\n",
      "batch_normalization_54 False\n",
      "activation_54 False\n",
      "conv2d_55 False\n",
      "batch_normalization_55 False\n",
      "activation_55 False\n",
      "conv2d_51 False\n",
      "conv2d_56 False\n",
      "batch_normalization_51 False\n",
      "batch_normalization_56 False\n",
      "activation_51 False\n",
      "activation_56 False\n",
      "conv2d_52 False\n",
      "conv2d_57 False\n",
      "batch_normalization_52 False\n",
      "batch_normalization_57 False\n",
      "activation_52 False\n",
      "activation_57 False\n",
      "average_pooling2d_5 False\n",
      "conv2d_50 False\n",
      "conv2d_53 False\n",
      "conv2d_58 False\n",
      "conv2d_59 False\n",
      "batch_normalization_50 False\n",
      "batch_normalization_53 False\n",
      "batch_normalization_58 False\n",
      "batch_normalization_59 False\n",
      "activation_50 False\n",
      "activation_53 False\n",
      "activation_58 False\n",
      "activation_59 False\n",
      "mixed6 False\n",
      "conv2d_64 False\n",
      "batch_normalization_64 False\n",
      "activation_64 False\n",
      "conv2d_65 False\n",
      "batch_normalization_65 False\n",
      "activation_65 False\n",
      "conv2d_61 False\n",
      "conv2d_66 False\n",
      "batch_normalization_61 False\n",
      "batch_normalization_66 False\n",
      "activation_61 False\n",
      "activation_66 False\n",
      "conv2d_62 False\n",
      "conv2d_67 False\n",
      "batch_normalization_62 False\n",
      "batch_normalization_67 False\n",
      "activation_62 False\n",
      "activation_67 False\n",
      "average_pooling2d_6 False\n",
      "conv2d_60 False\n",
      "conv2d_63 False\n",
      "conv2d_68 False\n",
      "conv2d_69 False\n",
      "batch_normalization_60 False\n",
      "batch_normalization_63 False\n",
      "batch_normalization_68 False\n",
      "batch_normalization_69 False\n",
      "activation_60 False\n",
      "activation_63 False\n",
      "activation_68 False\n",
      "activation_69 False\n",
      "mixed7 False\n",
      "conv2d_72 False\n",
      "batch_normalization_72 False\n",
      "activation_72 False\n",
      "conv2d_73 False\n",
      "batch_normalization_73 False\n",
      "activation_73 False\n",
      "conv2d_70 False\n",
      "conv2d_74 False\n",
      "batch_normalization_70 False\n",
      "batch_normalization_74 False\n",
      "activation_70 False\n",
      "activation_74 False\n",
      "conv2d_71 False\n",
      "conv2d_75 False\n",
      "batch_normalization_71 False\n",
      "batch_normalization_75 False\n",
      "activation_71 False\n",
      "activation_75 False\n",
      "max_pooling2d_3 False\n",
      "mixed8 False\n",
      "conv2d_80 False\n",
      "batch_normalization_80 False\n",
      "activation_80 False\n",
      "conv2d_77 False\n",
      "conv2d_81 False\n",
      "batch_normalization_77 False\n",
      "batch_normalization_81 False\n",
      "activation_77 False\n",
      "activation_81 False\n",
      "conv2d_78 False\n",
      "conv2d_79 False\n",
      "conv2d_82 False\n",
      "conv2d_83 True\n",
      "average_pooling2d_7 True\n",
      "conv2d_76 True\n",
      "batch_normalization_78 True\n",
      "batch_normalization_79 True\n",
      "batch_normalization_82 True\n",
      "batch_normalization_83 True\n",
      "conv2d_84 True\n",
      "batch_normalization_76 True\n",
      "activation_78 True\n",
      "activation_79 True\n",
      "activation_82 True\n",
      "activation_83 True\n",
      "batch_normalization_84 True\n",
      "activation_76 True\n",
      "mixed9_0 True\n",
      "concatenate True\n",
      "activation_84 True\n",
      "mixed9 True\n",
      "conv2d_89 True\n",
      "batch_normalization_89 True\n",
      "activation_89 True\n",
      "conv2d_86 True\n",
      "conv2d_90 True\n",
      "batch_normalization_86 True\n",
      "batch_normalization_90 True\n",
      "activation_86 True\n",
      "activation_90 True\n",
      "conv2d_87 True\n",
      "conv2d_88 True\n",
      "conv2d_91 True\n",
      "conv2d_92 True\n",
      "average_pooling2d_8 True\n",
      "conv2d_85 True\n",
      "batch_normalization_87 True\n",
      "batch_normalization_88 True\n",
      "batch_normalization_91 True\n",
      "batch_normalization_92 True\n",
      "conv2d_93 True\n",
      "batch_normalization_85 True\n",
      "activation_87 True\n",
      "activation_88 True\n",
      "activation_91 True\n",
      "activation_92 True\n",
      "batch_normalization_93 True\n",
      "activation_85 True\n",
      "mixed9_1 True\n",
      "concatenate_1 True\n",
      "activation_93 True\n",
      "mixed10 True\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:44:21.116262693Z",
     "start_time": "2024-03-23T17:44:21.110193093Z"
    }
   },
   "id": "396cc7ef6dbc7bae",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 2.3589 - accuracy: 0.2712\n",
      "Epoch 11: val_loss improved from 2.32850 to 2.24982, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 39s 63ms/step - loss: 2.3589 - accuracy: 0.2711 - val_loss: 2.2498 - val_accuracy: 0.3048 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "564/564 [==============================] - ETA: 0s - loss: 2.2281 - accuracy: 0.2960\n",
      "Epoch 12: val_loss improved from 2.24982 to 2.05184, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 35s 63ms/step - loss: 2.2281 - accuracy: 0.2960 - val_loss: 2.0518 - val_accuracy: 0.3145 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "564/564 [==============================] - ETA: 0s - loss: 2.1407 - accuracy: 0.3096\n",
      "Epoch 13: val_loss improved from 2.05184 to 2.01768, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 35s 62ms/step - loss: 2.1407 - accuracy: 0.3096 - val_loss: 2.0177 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 2.0693 - accuracy: 0.3292\n",
      "Epoch 14: val_loss improved from 2.01768 to 2.00009, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 36s 63ms/step - loss: 2.0691 - accuracy: 0.3293 - val_loss: 2.0001 - val_accuracy: 0.3385 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 2.0084 - accuracy: 0.3453\n",
      "Epoch 15: val_loss improved from 2.00009 to 1.86701, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 35s 63ms/step - loss: 2.0084 - accuracy: 0.3453 - val_loss: 1.8670 - val_accuracy: 0.3408 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "564/564 [==============================] - ETA: 0s - loss: 1.9289 - accuracy: 0.3650\n",
      "Epoch 16: val_loss improved from 1.86701 to 1.85579, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 35s 63ms/step - loss: 1.9289 - accuracy: 0.3650 - val_loss: 1.8558 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "564/564 [==============================] - ETA: 0s - loss: 1.9102 - accuracy: 0.3741\n",
      "Epoch 17: val_loss improved from 1.85579 to 1.84789, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 35s 62ms/step - loss: 1.9102 - accuracy: 0.3741 - val_loss: 1.8479 - val_accuracy: 0.3835 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 1.8234 - accuracy: 0.3979\n",
      "Epoch 18: val_loss improved from 1.84789 to 1.70194, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 35s 63ms/step - loss: 1.8237 - accuracy: 0.3979 - val_loss: 1.7019 - val_accuracy: 0.4272 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "564/564 [==============================] - ETA: 0s - loss: 1.8014 - accuracy: 0.4055\n",
      "Epoch 19: val_loss did not improve from 1.70194\n",
      "564/564 [==============================] - 35s 62ms/step - loss: 1.8014 - accuracy: 0.4055 - val_loss: 1.7070 - val_accuracy: 0.4239 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 1.7227 - accuracy: 0.4262\n",
      "Epoch 20: val_loss improved from 1.70194 to 1.59768, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 35s 62ms/step - loss: 1.7225 - accuracy: 0.4263 - val_loss: 1.5977 - val_accuracy: 0.4880 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 1.7106 - accuracy: 0.4322\n",
      "Epoch 21: val_loss improved from 1.59768 to 1.58459, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 38s 68ms/step - loss: 1.7112 - accuracy: 0.4322 - val_loss: 1.5846 - val_accuracy: 0.4557 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "564/564 [==============================] - ETA: 0s - loss: 1.6559 - accuracy: 0.4504\n",
      "Epoch 22: val_loss did not improve from 1.58459\n",
      "564/564 [==============================] - 39s 68ms/step - loss: 1.6559 - accuracy: 0.4504 - val_loss: 1.5992 - val_accuracy: 0.4439 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 1.5925 - accuracy: 0.4643\n",
      "Epoch 23: val_loss improved from 1.58459 to 1.56718, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 39s 69ms/step - loss: 1.5924 - accuracy: 0.4643 - val_loss: 1.5672 - val_accuracy: 0.4738 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 1.5830 - accuracy: 0.4759\n",
      "Epoch 24: val_loss did not improve from 1.56718\n",
      "564/564 [==============================] - 39s 68ms/step - loss: 1.5833 - accuracy: 0.4758 - val_loss: 1.7365 - val_accuracy: 0.4119 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "563/564 [============================>.] - ETA: 0s - loss: 1.5562 - accuracy: 0.4862\n",
      "Epoch 25: val_loss improved from 1.56718 to 1.42279, saving model to Best_models/best_inceptionv3.hdf5\n",
      "564/564 [==============================] - 39s 69ms/step - loss: 1.5561 - accuracy: 0.4862 - val_loss: 1.4228 - val_accuracy: 0.5488 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x7943e0147880>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "                           optimizer=Adam(),\n",
    "                           metrics=['accuracy'])\n",
    "start_epoch = 10\n",
    "\n",
    "model1.fit(train_dataset,\n",
    "                                        validation_data=validation_dataset,\n",
    "                                        epochs=start_epoch+15,\n",
    "                                        initial_epoch=start_epoch, \n",
    "                                        verbose=1,\n",
    "                                        callbacks=[checkpointer, lr_scheduler]) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:53:31.006322193Z",
     "start_time": "2024-03-23T17:44:21.115837536Z"
    }
   },
   "id": "203e49fb2dead93f",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "311"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_model.layers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:53:31.010947416Z",
     "start_time": "2024-03-23T17:53:31.007075486Z"
    }
   },
   "id": "6ecf65f6cb6daf4e",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "for layer in base_model.layers[-290:]:\n",
    "    layer.trainable = True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T18:16:04.741874588Z",
     "start_time": "2024-03-23T18:16:04.698554535Z"
    }
   },
   "id": "c9c1648ec5fea6af",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/145\n",
      "563/564 [============================>.] - ETA: 0s - loss: 0.2877 - accuracy: 0.9021\n",
      "Epoch 116: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 39s 63ms/step - loss: 0.2878 - accuracy: 0.9020 - val_loss: 0.6235 - val_accuracy: 0.8795 - lr: 6.2500e-05\n",
      "Epoch 117/145\n",
      "564/564 [==============================] - ETA: 0s - loss: 0.2850 - accuracy: 0.9044\n",
      "Epoch 117: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 35s 62ms/step - loss: 0.2850 - accuracy: 0.9044 - val_loss: 0.6349 - val_accuracy: 0.8826 - lr: 6.2500e-05\n",
      "Epoch 118/145\n",
      "563/564 [============================>.] - ETA: 0s - loss: 0.2875 - accuracy: 0.9029\n",
      "Epoch 118: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 35s 63ms/step - loss: 0.2875 - accuracy: 0.9029 - val_loss: 0.6238 - val_accuracy: 0.8770 - lr: 6.2500e-05\n",
      "Epoch 119/145\n",
      "564/564 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.9024\n",
      "Epoch 119: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 35s 62ms/step - loss: 0.2867 - accuracy: 0.9024 - val_loss: 0.6230 - val_accuracy: 0.8787 - lr: 6.2500e-05\n",
      "Epoch 120/145\n",
      "563/564 [============================>.] - ETA: 0s - loss: 0.2802 - accuracy: 0.9060\n",
      "Epoch 120: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 36s 63ms/step - loss: 0.2801 - accuracy: 0.9060 - val_loss: 0.6167 - val_accuracy: 0.8783 - lr: 6.2500e-05\n",
      "Epoch 121/145\n",
      "564/564 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.9019\n",
      "Epoch 121: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 36s 63ms/step - loss: 0.2828 - accuracy: 0.9019 - val_loss: 0.6328 - val_accuracy: 0.8824 - lr: 6.2500e-05\n",
      "Epoch 122/145\n",
      "564/564 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.9044\n",
      "Epoch 122: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 36s 63ms/step - loss: 0.2824 - accuracy: 0.9044 - val_loss: 0.6173 - val_accuracy: 0.8809 - lr: 6.2500e-05\n",
      "Epoch 123/145\n",
      "563/564 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.9073\n",
      "Epoch 123: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 36s 64ms/step - loss: 0.2734 - accuracy: 0.9073 - val_loss: 0.6222 - val_accuracy: 0.8884 - lr: 6.2500e-05\n",
      "Epoch 124/145\n",
      "564/564 [==============================] - ETA: 0s - loss: 0.2727 - accuracy: 0.9068\n",
      "Epoch 124: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 35s 63ms/step - loss: 0.2727 - accuracy: 0.9068 - val_loss: 0.6285 - val_accuracy: 0.8836 - lr: 3.1250e-05\n",
      "Epoch 125/145\n",
      "564/564 [==============================] - ETA: 0s - loss: 0.2663 - accuracy: 0.9083\n",
      "Epoch 125: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 35s 63ms/step - loss: 0.2663 - accuracy: 0.9083 - val_loss: 0.6043 - val_accuracy: 0.8844 - lr: 3.1250e-05\n",
      "Epoch 126/145\n",
      "563/564 [============================>.] - ETA: 0s - loss: 0.2659 - accuracy: 0.9070\n",
      "Epoch 126: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 35s 63ms/step - loss: 0.2659 - accuracy: 0.9069 - val_loss: 0.6233 - val_accuracy: 0.8836 - lr: 3.1250e-05\n",
      "Epoch 127/145\n",
      "564/564 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.9089\n",
      "Epoch 127: val_loss did not improve from 0.59865\n",
      "564/564 [==============================] - 35s 63ms/step - loss: 0.2632 - accuracy: 0.9089 - val_loss: 0.6245 - val_accuracy: 0.8835 - lr: 3.1250e-05\n",
      "Epoch 128/145\n",
      "532/564 [===========================>..] - ETA: 1s - loss: 0.2656 - accuracy: 0.9088"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m model1\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      2\u001B[0m                            optimizer\u001B[38;5;241m=\u001B[39mAdam(\u001B[38;5;241m0.0000625\u001B[39m),\n\u001B[1;32m      3\u001B[0m                            metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      4\u001B[0m start_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m115\u001B[39m\n\u001B[0;32m----> 6\u001B[0m \u001B[43mmodel1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m                                        \u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                                        \u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_epoch\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpointer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1266\u001B[0m     args,\n\u001B[1;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1268\u001B[0m     executing_eagerly)\n\u001B[1;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    262\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1494\u001B[0m   )\n",
      "File \u001B[0;32m~/PycharmProjects/BIRD_CLASSIFICATION/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[1;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[1;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[1;32m     59\u001B[0m   ]\n\u001B[0;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "                           optimizer=Adam(0.0000625),\n",
    "                           metrics=['accuracy'])\n",
    "start_epoch = 115\n",
    "\n",
    "model1.fit(train_dataset,\n",
    "                                        \n",
    "                                        validation_data=validation_dataset,\n",
    "                                        \n",
    "                                        epochs=start_epoch+30,\n",
    "                                        initial_epoch=start_epoch, \n",
    "                                        verbose=1,\n",
    "                                        callbacks=[checkpointer, lr_scheduler]) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T19:10:32.482866926Z",
     "start_time": "2024-03-23T19:02:58.378861701Z"
    }
   },
   "id": "686cc96cfff8e778",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "361/361 [==============================] - 18s 47ms/step - loss: 0.9676 - accuracy: 0.8368\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.9676294922828674, 0.8368124961853027]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = tf.keras.models.load_model(\"Best_models/best_inceptionv3.hdf5\")\n",
    "loaded.evaluate(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T19:10:52.897948323Z",
     "start_time": "2024-03-23T19:10:33.793250411Z"
    }
   },
   "id": "4a4be18eae3ba236",
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
